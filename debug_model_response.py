#!/usr/bin/env python3
"""
Debug Model Response
===================

This script tests if the model is actually generating responses or just returning raw content.
"""

import os
import traceback


def debug_model_response():
    """Debug the model response generation"""
    print("ğŸ” Debugging Model Response Generation...")

    # Check environment variables
    hf_api_key = os.getenv("HF_API_KEY")
    pinecone_api_key = os.getenv("PINECONE_API_KEY")

    print(f"HF_API_KEY set: {'Yes' if hf_api_key else 'No'}")
    print(f"PINECONE_API_KEY set: {'Yes' if pinecone_api_key else 'No'}")

    if not hf_api_key:
        print("âŒ Error: HF_API_KEY environment variable not set")
        print("Please set your Hugging Face API key:")
        print("export HF_API_KEY=your_api_key_here")
        return False

    if not pinecone_api_key:
        print("âŒ Error: PINECONE_API_KEY environment variable not set")
        print("Please set your Pinecone API key:")
        print("export PINECONE_API_KEY=your_api_key_here")
        return False

    try:
        print("\nğŸ“¦ Importing modules...")
        from advanced_rag_system_pinecone import AdvancedRAGSystem, ModelType
        print("âœ… Modules imported successfully")

        # Initialize RAG system
        print("\nğŸ”§ Initializing RAG system...")
        rag_system = AdvancedRAGSystem(
            index_name="belle2-advanced",
            use_integrated_embeddings=False
        )
        print("âœ… RAG system initialized")

        # Test query
        query = "How was integrated luminosity measured during Belle II Phase 2, and what are the key processes used?"

        print(f"\nğŸ“ Query: {query}")

        # Retrieve documents
        print("\nğŸ” Retrieving documents...")
        retrieval_results = rag_system.retrieve(
            query, strategy="hybrid", top_k=3)

        print(f"âœ… Retrieved {len(retrieval_results)} documents")

        # Show retrieved content
        print("\nğŸ“š Retrieved Content:")
        for i, result in enumerate(retrieval_results, 1):
            print(f"\n--- Document {i} ---")
            print(f"Document: {result.document}")
            print(f"Page: {result.page_number}")
            print(f"Type: {result.chunk_type}")
            print(f"Score: {result.similarity_score:.3f}")
            print(f"Content: {result.content[:200]}...")

        # Generate prompt
        print("\nğŸ¤– Generating prompt...")
        prompt = rag_system._compose_advanced_prompt(query, retrieval_results)

        print(f"\nğŸ“‹ Prompt Length: {len(prompt)} characters")
        print(f"ğŸ“‹ Prompt Preview: {prompt[:500]}...")

        # Test model response
        print("\nğŸ¤– Testing model response...")
        response = rag_system.generate_answer(
            query,
            retrieval_results,
            model_type=ModelType.MISTRAL_7B,
            temperature=0.1
        )

        print(f"\nâœ… Model Response:")
        print(f"Answer: {response.answer}")
        print(f"Model Used: {response.model_used}")
        print(f"Processing Time: {response.processing_time:.2f}s")
        print(f"Confidence: {response.confidence_score:.3f}")

        # Check if response looks like raw content
        print(f"\nğŸ” Response Analysis:")
        print(f"Response Length: {len(response.answer)} characters")

        # Check for common patterns that indicate raw content vs generated response
        if "TEXT CONTENT:" in response.answer or "Text 1 (from" in response.answer:
            print("âš ï¸  WARNING: Response appears to contain raw prompt content!")
        elif "Reference:" in response.answer and "pages" in response.answer:
            print("âš ï¸  WARNING: Response appears to be copied from source!")
        else:
            print("âœ… Response appears to be properly generated by the model")

        return True

    except Exception as e:
        print(f"âŒ Error: {e}")
        print("\nğŸ” Full traceback:")
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("ğŸš€ Debugging Model Response")
    print("=" * 40)

    success = debug_model_response()

    if success:
        print("\nâœ… Debug completed!")
    else:
        print("\nâŒ Debug failed!")
